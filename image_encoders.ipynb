{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk_grOvN_oZa"
      },
      "outputs": [],
      "source": [
        "# pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4x096EwtIL2d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm.auto import tqdm\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from PIL import Image\n",
        "import os\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RhAuhlTmIU9x"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ftfy or spacy is not installed using BERT BasicTokenizer instead of ftfy.\n"
          ]
        }
      ],
      "source": [
        "resnet50 = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
        "xception = Xception(include_top=False, weights='imagenet', pooling='avg')\n",
        "vgg19 = VGG19(include_top=False, weights='imagenet', pooling='avg')\n",
        "inceptionv3 = InceptionV3(include_top=False, weights='imagenet', pooling='avg')\n",
        "densenet = DenseNet121(include_top=False, weights='imagenet', pooling='avg')\n",
        "clip = SentenceTransformer('clip-ViT-B-32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "twgF1WXLISh2"
      },
      "outputs": [],
      "source": [
        "def return_image_embedding(model,img_path):\n",
        "    if model != clip:\n",
        "        img = image.load_img(img_path, target_size=(224, 224))\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = preprocess_input(x)\n",
        "        preds = model.predict(x)\n",
        "        curr_df = pd.DataFrame(preds[0])\n",
        "        curr_df = list(curr_df[0])\n",
        "    else:\n",
        "        curr_df = list(clip.encode(Image.open(img_path)))\n",
        "    return curr_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def files(path):\n",
        "    for file in os.listdir(path):\n",
        "        if os.path.isfile(os.path.join(path, file)):\n",
        "            yield file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "img_path = train_img_path + \"/\" + img_list[0]\n",
        "model = densenet\n",
        "return_image_embedding(model,img_path)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_img_encoding_file(train_img_path,count_img,model,model_name):\n",
        "    i = 1\n",
        "    file_num = 0\n",
        "    list_img = []\n",
        "    list_encodings = []\n",
        "\n",
        "\n",
        "    for img in tqdm.tqdm(list(files(path = train_img_path))):\n",
        "\n",
        "        img_path = train_img_path + \"/\" + img\n",
        "        list_img.append(int(img[:-4]))\n",
        "        list_encodings.append(return_image_embedding(model,img_path))\n",
        "\n",
        "        if (i % count_img) == 0:\n",
        "            df = pd.DataFrame(list_encodings)\n",
        "            df['img'] = list_img\n",
        "            df.columns = df.columns.map(str)\n",
        "\n",
        "            file_name = \"./img_encodings/train_img_encodings_\" + f\"{model_name}\" + \"_\" + f\"{file_num}\" + \".parquet\"\n",
        "\n",
        "            df.to_parquet(file_name)  \n",
        "\n",
        "            file_num = file_num + 1\n",
        "            i = 1\n",
        "\n",
        "            list_img = []\n",
        "            list_encodings = []\n",
        "\n",
        "        else:\n",
        "\n",
        "            i = i + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_img_path = \"./coco/images/train2017\"\n",
        "count_img = 10\n",
        "model = densenet\n",
        "model_name = 'densenet'\n",
        "\n",
        "get_img_encoding_file(train_img_path,count_img,model,model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "restored_df = pd.read_parquet(path = './img_encodings//train_img_encodings_densenet_0.parquet')\n",
        "restored_df\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
